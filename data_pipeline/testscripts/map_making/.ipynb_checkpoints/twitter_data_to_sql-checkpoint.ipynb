{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import psycopg2\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Get Data From JSON File. Put Into Database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1. Import Data\n",
    "notes to self: if file is empty, or json object is incomplete, it may get mad. What can I do about this?\n",
    "\n",
    "A. ONE FILE\n",
    "\n",
    "B. ALL FILES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#time.sleep(2000)\n",
    "#all the tweet files from one week\n",
    "tweet_files= glob.glob('../../../../../Desktop/toomanytweets/*json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def json_to_df(filename):\n",
    "    '''Takes in a json file. Returns a pandas dataframe'''\n",
    "    with open(filename, 'r') as f:\n",
    "        l = f.readlines()\n",
    "\n",
    "    data = [json.loads(s) for s in l]\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "#df_tweets = json_to_df(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_mega_dataframe(filepath):\n",
    "    '''Takes a filepath to a directory of json files for twitterdata\n",
    "    Runs through all the files, reads them into a pandas dataframe, \n",
    "    and returns a mega-dataframe of all the json files appended together'''\n",
    "    tweet_files= glob.glob(filepath)\n",
    "    df = json_to_df(tweet_files[0])\n",
    "    for tf in tweet_files[1:]:\n",
    "        temp_df = json_to_df(tf)\n",
    "        df = df.append(temp_df)      \n",
    "    return df\n",
    "\n",
    "df_tweets = get_mega_dataframe('../../../../../Desktop/toomanytweets/*json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2. Format Data to Put in Database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_columns(df):\n",
    "    '''Called by clean_text_for_sql. Takes in a pandas dataframe. Returns a smaller dataframe:\n",
    "    Text, Coordinates, timestamp'''\n",
    "    #only include rows with coordinates\n",
    "    df = df[~df['coordinates'].isnull()]\n",
    "    #make a new dataframe with coordinates, tweets, and timestamps\n",
    "    df = df[['coordinates', 'text' ,'timestamp_ms']]\n",
    "    #get a list of coordinates to break it into long and lat data\n",
    "    coor = df.coordinates.tolist()\n",
    "    #list of the longitude coordinates\n",
    "    lons = [c['coordinates'][0] for c in coor]\n",
    "    #list of the latitude coordinates \n",
    "    lats = [c['coordinates'][1] for c in coor]\n",
    "    \n",
    "    #turn lats and longs into panda series. Append them to the dataframe.\n",
    "    df['lons'] = pd.Series(lons)\n",
    "    df['lats'] = pd.Series(lats)\n",
    "    df = df.drop('coordinates', 1)   \n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_text_for_sql(df):\n",
    "    '''Takes in a dataframe with a text column containing emoticons, ect. \n",
    "    Returns a dataframe where the text has been striped of punctuation and repeats\n",
    "    Also reorders the columns to fit the order I want for SQL'''\n",
    "    df = extract_columns(df)\n",
    "    df['text'] = [re.sub('[^A-Za-z0-9]+', ' ',s)for s in df.text.tolist()]\n",
    "    df.columns.tolist()          \n",
    "    ordered_colums = [u'timestamp_ms',u'text', 'lats', 'lons' ]\n",
    "    return df[ordered_colums]\n",
    "\n",
    "\n",
    "df_ordered = clean_text_for_sql(df_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3. Export The DF Into a  SQL Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'timestamp_ms', u'text', u'lats', u'lons'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ordered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72023, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ordered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71833, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twitter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drop rows if there are repeats \n",
    "df_twitter = df_ordered.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71833, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twitter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_twitter.to_csv('tweets_cleaned.csv', encoding = 'utf-8', index = False, header=False, if_exists ='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Alternative method: Use SQLalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://clwilloughby:christy@localhost:5432/zipfiantwitter')\n",
    "df_twitter.to_sql(\"tweetedBIGwk2\", engine, if_exists='replace')\n",
    "#when I do this, NOW THE THING HAS TO BE IN QUOTES. OOPS. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#FORMAT THE CSV IN SQL TO GET COORDINATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname='zipfiantwitter', user ='clwilloughby', host = '/tmp')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\" SELECT AddGeometryColumn('tweetedBIGwk2','geom',4326,'POINT',2);\"\"\"\n",
    "c.execute(query)\n",
    "conn.commit()\n",
    "print 'done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(dbname='zipfiantwitter', user ='clwilloughby', host = '/tmp')\n",
    "c = conn.cursor()\n",
    "query = \"\"\"UPDATE \"tweetedBIGwk2\" SET geom = ST_SetSRID(ST_MakePoint(lons, lats), 4326);\"\"\"\n",
    "c.execute(query)\n",
    "conn.commit()            \n",
    "print 'done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(dbname='zipfiantwitter', user ='clwilloughby', host = '/tmp')\n",
    "c = conn.cursor()\n",
    "query = \"\"\"SELECT UpdateGeometrySRID('sf_neighb', 'wkb_geometry', 4326);\"\"\" \n",
    "c.execute(query)\n",
    "conn.commit() \n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(dbname='zipfiantwitter', user ='clwilloughby', host = '/tmp')\n",
    "c = conn.cursor()\n",
    "query = \"\"\" SELECT points.*, polys.geoid10\n",
    "                INTO tweeted_neighb_wk2 \n",
    "                FROM sf_neighb polys\n",
    "                JOIN \"tweetedBIGwk2\" points \n",
    "                ON ST_Within(points.geom,polys.wkb_geometry);\"\"\"\n",
    "c.execute(query)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "print 'done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Option 2: Send it to a CSV!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Commands entered in postgress\n",
    "\n",
    "```psql\n",
    "CREATE DATABASE zipfiantwitter\n",
    "\\l```\n",
    "\n",
    "Things became obnoxious and i changed things:\n",
    "\n",
    "```sql\n",
    "CREATE TABLE tweet(\n",
    "    timestamp_ms bigint,\n",
    "    text varchar(255),\n",
    "    lats FLOAT,\n",
    "    lons FLOAT\n",
    "    );\n",
    "    \n",
    "COPY tweeting FROM '/Users/clwilloughby/Documents/root/repos/media_mapper/map_tests/postgress_exp/data_for_sql.csv' WITH (FORMAT CSV, DELIMETER ',');\n",
    "```\n",
    "   ```\n",
    "   \n",
    "If I need to change the column type:\n",
    "```sql\n",
    "ALTER COLUMN timestamp_ms SET DATA TYPE bigint ;\n",
    "ALTER COLUMN presales TYPE numeric\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
