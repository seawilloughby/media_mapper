{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import psycopg2\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Get Data From JSON File. Put Into Database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1. Import Data\n",
    "notes to self: if file is empty, or json object is incomplete, it may get mad. What can I do about this?\n",
    "\n",
    "A. ONE FILE\n",
    "\n",
    "B. ALL FILES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#time.sleep(2000)\n",
    "#all the tweet files from one week\n",
    "tweet_files= glob.glob('../../../../../Desktop/toomanytweets/*json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def json_to_df(filename):\n",
    "    '''Takes in a json file. Returns a pandas dataframe'''\n",
    "    with open(filename, 'r') as f:\n",
    "        l = f.readlines()\n",
    "\n",
    "    data = [json.loads(s) for s in l]\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "#df_tweets = json_to_df(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_mega_dataframe(filepath):\n",
    "    '''Takes a filepath to a directory of json files for twitterdata\n",
    "    Runs through all the files, reads them into a pandas dataframe, \n",
    "    and returns a mega-dataframe of all the json files appended together'''\n",
    "    tweet_files= glob.glob(filepath)\n",
    "    df = json_to_df(tweet_files[0])\n",
    "    for tf in tweet_files[1:]:\n",
    "        temp_df = json_to_df(tf)\n",
    "        df = df.append(temp_df)      \n",
    "    return df\n",
    "\n",
    "df_tweets = get_mega_dataframe('../../../../../Desktop/toomanytweets/*json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_cleaned = extract_columns(df_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173455, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer.simpleTokenize(teststring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_cleaned.to_csv('jsontweets_in_df.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2. Format Data to Put in Database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_columns(df):\n",
    "    '''Called by clean_text_for_sql. Takes in a pandas dataframe. Returns a smaller dataframe:\n",
    "    Text, Coordinates, timestamp'''\n",
    "    #only include rows with coordinates\n",
    "    df = df[~df['coordinates'].isnull()]\n",
    "    #make a new dataframe with coordinates, tweets, and timestamps\n",
    "    df = df[['coordinates', 'text' ,'timestamp_ms']]\n",
    "    #get a list of coordinates to break it into long and lat data\n",
    "    coor = df.coordinates.tolist()\n",
    "    #list of the longitude coordinates\n",
    "    lons = [c['coordinates'][0] for c in coor]\n",
    "    #list of the latitude coordinates \n",
    "    lats = [c['coordinates'][1] for c in coor]\n",
    "    \n",
    "    #turn lats and longs into panda series. Append them to the dataframe.\n",
    "    df['lons'] = pd.Series(lons)\n",
    "    df['lats'] = pd.Series(lats)\n",
    "    df = df.drop('coordinates', 1)   \n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text_for_sql(df):\n",
    "    '''Takes in a dataframe with a text column containing emoticons, ect. \n",
    "    Returns a dataframe where the text has been striped of punctuation and repeats\n",
    "    Also reorders the columns to fit the order I want for SQL'''\n",
    "    df = extract_columns(df)\n",
    "    df['text'] = [re.sub('[^A-Za-z0-9]+', ' ',s)for s in df.text.tolist()]\n",
    "    df.columns.tolist()          \n",
    "    ordered_colums = [u'timestamp_ms',u'text', 'lats', 'lons' ]\n",
    "    return df[ordered_colums]\n",
    "\n",
    "\n",
    "df_ordered = clean_text_for_sql(df_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize_text(df):\n",
    "    '''Takes in a dataframe with a text column containing emoticons, ect. \n",
    "    Returns a dataframe where the text has been striped of punctuation and repeats\n",
    "    Also reorders the columns to fit the order I want for SQL'''\n",
    "    df['text'] = [tokenizer.simpleTokenize(s) for s in df.text.tolist()]\n",
    "    df.columns.tolist()          \n",
    "    ordered_colums = [u'timestamp_ms',u'text', 'lats', 'lons' ]\n",
    "    return df[ordered_colums]\n",
    "\n",
    "\n",
    "#df_ordered = tokenize_text(df_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christy/miniconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "new = tokenize_text(df_cleaned[10:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cleaned.to_csv('jsontweets_in_df_twitokend.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>lons</th>\n",
       "      <th>lats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[“, @h1_k4r1, :, Watching, Emo, Philips, until...</td>\n",
       "      <td>1437858793555</td>\n",
       "      <td>-122.444437</td>\n",
       "      <td>37.455230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[More, beauty, ., #merica, #USA, #california, ...</td>\n",
       "      <td>1437871994025</td>\n",
       "      <td>-119.594708</td>\n",
       "      <td>37.744593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[I'm, at, @Google, San, Francisco, in, San, Fr...</td>\n",
       "      <td>1436990735491</td>\n",
       "      <td>-122.425183</td>\n",
       "      <td>37.798493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[TURN, UP, !!, C3SV, Palo, Alto, SQUAD, taking...</td>\n",
       "      <td>1437954606236</td>\n",
       "      <td>-122.271114</td>\n",
       "      <td>37.804364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[Clear, sky, view, of, SF, @, Alta, Plaza, Par...</td>\n",
       "      <td>1437945824772</td>\n",
       "      <td>-118.817803</td>\n",
       "      <td>34.092212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[&amp;, amp, ;, don't, 4, get, 2, dream, pretty, ....</td>\n",
       "      <td>1438143406505</td>\n",
       "      <td>-121.926666</td>\n",
       "      <td>37.367079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[http://t.co/aGnxhinfIM]</td>\n",
       "      <td>1438041259509</td>\n",
       "      <td>-122.419225</td>\n",
       "      <td>37.799061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[Re, :, A, Thousand, Islands, ,, A, Hundred, H...</td>\n",
       "      <td>1436985606549</td>\n",
       "      <td>-122.700836</td>\n",
       "      <td>38.752335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>[a, gentleman's, quarters, at, #Alcatraz, #The...</td>\n",
       "      <td>1437873474604</td>\n",
       "      <td>-118.976018</td>\n",
       "      <td>37.627002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>[This, #Engineering, #job, might, be, a, great...</td>\n",
       "      <td>1437850876932</td>\n",
       "      <td>-122.414169</td>\n",
       "      <td>37.605369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>[Disabled, vehicle, ,, center, lane, blocked, ...</td>\n",
       "      <td>1436997725819</td>\n",
       "      <td>-121.960023</td>\n",
       "      <td>37.301513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>[Спой, ,, птичка, ,, не, стыдись, ..., В, #San...</td>\n",
       "      <td>1437929054749</td>\n",
       "      <td>-122.373690</td>\n",
       "      <td>37.729814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>[Too, slow, on, the, draw, !, This, snake, cro...</td>\n",
       "      <td>1438035107055</td>\n",
       "      <td>-122.402977</td>\n",
       "      <td>37.802200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>[#CareerArc, #Marketing, #Job, alert, :, Direc...</td>\n",
       "      <td>1437846749895</td>\n",
       "      <td>-121.894956</td>\n",
       "      <td>37.339386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>[Drinking, an, Old, Rasputin, by, @NoCoastBrew...</td>\n",
       "      <td>1437850920740</td>\n",
       "      <td>-122.252258</td>\n",
       "      <td>37.850349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>[#thaitea, @, Veggie, Lee, https://t.co/PHRmxd...</td>\n",
       "      <td>1437877662170</td>\n",
       "      <td>-122.419416</td>\n",
       "      <td>37.774930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>[Medical, Assistant, (, MARP, ), Alameda, -, P...</td>\n",
       "      <td>1436999040735</td>\n",
       "      <td>-121.894956</td>\n",
       "      <td>37.339386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>[IMG_9652, http://t.co/Y0YqxfsrPF]</td>\n",
       "      <td>1437922948347</td>\n",
       "      <td>-116.890000</td>\n",
       "      <td>35.426667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>[House, wine, served, right, ...., Wine, Barre...</td>\n",
       "      <td>1437836689910</td>\n",
       "      <td>-122.246333</td>\n",
       "      <td>37.481899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[William, Hill, Estate, Winery, ., Not, a, bad...</td>\n",
       "      <td>1437933539731</td>\n",
       "      <td>-123.012227</td>\n",
       "      <td>37.699616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text   timestamp_ms  \\\n",
       "3   [“, @h1_k4r1, :, Watching, Emo, Philips, until...  1437858793555   \n",
       "7   [More, beauty, ., #merica, #USA, #california, ...  1437871994025   \n",
       "25  [I'm, at, @Google, San, Francisco, in, San, Fr...  1436990735491   \n",
       "35  [TURN, UP, !!, C3SV, Palo, Alto, SQUAD, taking...  1437954606236   \n",
       "36  [Clear, sky, view, of, SF, @, Alta, Plaza, Par...  1437945824772   \n",
       "37  [&, amp, ;, don't, 4, get, 2, dream, pretty, ....  1438143406505   \n",
       "38                           [http://t.co/aGnxhinfIM]  1438041259509   \n",
       "46  [Re, :, A, Thousand, Islands, ,, A, Hundred, H...  1436985606549   \n",
       "52  [a, gentleman's, quarters, at, #Alcatraz, #The...  1437873474604   \n",
       "53  [This, #Engineering, #job, might, be, a, great...  1437850876932   \n",
       "60  [Disabled, vehicle, ,, center, lane, blocked, ...  1436997725819   \n",
       "67  [Спой, ,, птичка, ,, не, стыдись, ..., В, #San...  1437929054749   \n",
       "71  [Too, slow, on, the, draw, !, This, snake, cro...  1438035107055   \n",
       "73  [#CareerArc, #Marketing, #Job, alert, :, Direc...  1437846749895   \n",
       "76  [Drinking, an, Old, Rasputin, by, @NoCoastBrew...  1437850920740   \n",
       "77  [#thaitea, @, Veggie, Lee, https://t.co/PHRmxd...  1437877662170   \n",
       "84  [Medical, Assistant, (, MARP, ), Alameda, -, P...  1436999040735   \n",
       "88                 [IMG_9652, http://t.co/Y0YqxfsrPF]  1437922948347   \n",
       "89  [House, wine, served, right, ...., Wine, Barre...  1437836689910   \n",
       "99  [William, Hill, Estate, Winery, ., Not, a, bad...  1437933539731   \n",
       "\n",
       "          lons       lats  \n",
       "3  -122.444437  37.455230  \n",
       "7  -119.594708  37.744593  \n",
       "25 -122.425183  37.798493  \n",
       "35 -122.271114  37.804364  \n",
       "36 -118.817803  34.092212  \n",
       "37 -121.926666  37.367079  \n",
       "38 -122.419225  37.799061  \n",
       "46 -122.700836  38.752335  \n",
       "52 -118.976018  37.627002  \n",
       "53 -122.414169  37.605369  \n",
       "60 -121.960023  37.301513  \n",
       "67 -122.373690  37.729814  \n",
       "71 -122.402977  37.802200  \n",
       "73 -121.894956  37.339386  \n",
       "76 -122.252258  37.850349  \n",
       "77 -122.419416  37.774930  \n",
       "84 -121.894956  37.339386  \n",
       "88 -116.890000  35.426667  \n",
       "89 -122.246333  37.481899  \n",
       "99 -123.012227  37.699616  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3. Export The DF Into a  SQL Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'timestamp_ms', u'text', u'lats', u'lons'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ordered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72023, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ordered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71833, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twitter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drop rows if there are repeats \n",
    "df_twitter = df_ordered.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71833, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twitter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_twitter.to_csv('tweets_cleaned.csv', encoding = 'utf-8', index = False, header=False, if_exists ='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Alternative method: Use SQLalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://clwilloughby:christy@localhost:5432/zipfiantwitter')\n",
    "df_twitter.to_sql(\"tweetedBIGwk2\", engine, if_exists='replace')\n",
    "#when I do this, NOW THE THING HAS TO BE IN QUOTES. OOPS. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#FORMAT THE CSV IN SQL TO GET COORDINATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname='zipfiantwitter', user ='clwilloughby', host = '/tmp')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\" SELECT AddGeometryColumn('tweetedBIGwk2','geom',4326,'POINT',2);\"\"\"\n",
    "c.execute(query)\n",
    "conn.commit()\n",
    "print 'done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(dbname='zipfiantwitter', user ='clwilloughby', host = '/tmp')\n",
    "c = conn.cursor()\n",
    "query = \"\"\"UPDATE \"tweetedBIGwk2\" SET geom = ST_SetSRID(ST_MakePoint(lons, lats), 4326);\"\"\"\n",
    "c.execute(query)\n",
    "conn.commit()            \n",
    "print 'done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(dbname='zipfiantwitter', user ='clwilloughby', host = '/tmp')\n",
    "c = conn.cursor()\n",
    "query = \"\"\"SELECT UpdateGeometrySRID('sf_neighb', 'wkb_geometry', 4326);\"\"\" \n",
    "c.execute(query)\n",
    "conn.commit() \n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(dbname='zipfiantwitter', user ='clwilloughby', host = '/tmp')\n",
    "c = conn.cursor()\n",
    "query = \"\"\" SELECT points.*, polys.geoid10\n",
    "                INTO tweeted_neighb_wk2 \n",
    "                FROM sf_neighb polys\n",
    "                JOIN \"tweetedBIGwk2\" points \n",
    "                ON ST_Within(points.geom,polys.wkb_geometry);\"\"\"\n",
    "c.execute(query)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "print 'done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Option 2: Send it to a CSV!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Commands entered in postgress\n",
    "\n",
    "```psql\n",
    "CREATE DATABASE zipfiantwitter\n",
    "\\l```\n",
    "\n",
    "Things became obnoxious and i changed things:\n",
    "\n",
    "```sql\n",
    "CREATE TABLE tweet(\n",
    "    timestamp_ms bigint,\n",
    "    text varchar(255),\n",
    "    lats FLOAT,\n",
    "    lons FLOAT\n",
    "    );\n",
    "    \n",
    "COPY tweeting FROM '/Users/clwilloughby/Documents/root/repos/media_mapper/map_tests/postgress_exp/data_for_sql.csv' WITH (FORMAT CSV, DELIMETER ',');\n",
    "```\n",
    "   ```\n",
    "   \n",
    "If I need to change the column type:\n",
    "```sql\n",
    "ALTER COLUMN timestamp_ms SET DATA TYPE bigint ;\n",
    "ALTER COLUMN presales TYPE numeric\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
